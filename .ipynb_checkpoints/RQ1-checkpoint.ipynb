{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6fdc562c-06b6-470a-8bbf-bab7d17f6f54",
   "metadata": {},
   "source": [
    "### RQ1: Cross-Domain Transfer Learning for Pathological Motion Recognition.\n",
    "RQ1: Cross-Domain Transfer Learning for Pathological Motion Recognition. It builds on your UCI HAR baseline, adds self-supervised pretraining (SimCLR), and supports two domain-adaptation options:\n",
    "\n",
    "- DANN (adversarial domain alignment)\n",
    "\n",
    "- Contrastive alignment between source (healthy) and target (pathological) embeddings (class-prototype contrast + optional CORAL)\n",
    "\n",
    "It also includes a tiny synthetic pathological generator (more realistic tonic–clonic & absence) so you can test end-to-end immediately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "963a9a70-d951-4b8c-a28f-db12bcdf0a3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# ---- Core ----\n",
    "import os, math, random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ---- PyTorch ----\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# ---- Metrics ----\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix\n",
    "\n",
    "# ---- Repro/Device ----\n",
    "def set_seed(seed=42):\n",
    "    random.seed(seed); np.random.seed(seed)\n",
    "    torch.manual_seed(seed); torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "def device_autoselect():\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(\"Using device:\", device)\n",
    "    return device\n",
    "\n",
    "def ensure_dir(path): os.makedirs(path, exist_ok=True)\n",
    "\n",
    "set_seed(42)\n",
    "device = device_autoselect()\n",
    "ensure_dir(\"runs\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f75b08d5-1417-49fd-bc91-7a3a655dd8a9",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b82ba2f9-ac96-4fea-9743-302c648ee9f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class UCIHARDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Loader for UCI-HAR-style folders (also works for EpilepsyHAR_Realistic).\n",
    "    Returns x:[T,C] (float32), y:int label (0-based).\n",
    "    \"\"\"\n",
    "    def __init__(self, root: str, split: str = \"train\", use_inertial=True):\n",
    "        assert split in [\"train\",\"test\"]\n",
    "        inertial_dir = os.path.join(root, split, \"Inertial Signals\")\n",
    "        self.use_inertial = use_inertial and os.path.isdir(inertial_dir)\n",
    "        y_path = os.path.join(root, split, f\"y_{split}.txt\")\n",
    "        self.labels = np.loadtxt(y_path).astype(int).ravel()\n",
    "        if self.labels.min() == 1:  # shift 1..K -> 0..K-1 if needed\n",
    "            self.labels = self.labels - 1\n",
    "\n",
    "        if self.use_inertial:\n",
    "            sigs = [\n",
    "                \"total_acc_x_\",\"total_acc_y_\",\"total_acc_z_\",\n",
    "                \"body_acc_x_\",\"body_acc_y_\",\"body_acc_z_\",\n",
    "                \"body_gyro_x_\",\"body_gyro_y_\",\"body_gyro_z_\",\n",
    "            ]\n",
    "            arrays = [np.loadtxt(os.path.join(inertial_dir, s+split+\".txt\")) for s in sigs]\n",
    "            self.data = np.stack(arrays, axis=-1).astype(np.float32)  # [N,T,9]\n",
    "        else:\n",
    "            X_path = os.path.join(root, split, f\"X_{split}.txt\")      # 561-D features fallback\n",
    "            X = np.loadtxt(X_path).astype(np.float32)\n",
    "            self.data = X[:,:,None]                                   # [N,561,1]\n",
    "        assert len(self.data) == len(self.labels)\n",
    "\n",
    "    def __len__(self): return len(self.labels)\n",
    "    def __getitem__(self, idx):\n",
    "        x = torch.tensor(self.data[idx], dtype=torch.float32)  # [T,C]\n",
    "        y = torch.tensor(self.labels[idx], dtype=torch.long)\n",
    "        return x, y\n",
    "\n",
    "\n",
    "class TimeSeriesTransform:\n",
    "    \"\"\"Channel-wise normalization + optional augmentations for SSL.\"\"\"\n",
    "    def __init__(self, normalize=True, augment=False):\n",
    "        self.normalize = normalize\n",
    "        self.augment = augment\n",
    "        self.mean = None; self.std = None\n",
    "\n",
    "    def fit(self, data_array):  # [N,T,C]\n",
    "        flat = data_array.reshape(-1, data_array.shape[-1])\n",
    "        self.mean = flat.mean(axis=0); self.std = flat.std(axis=0) + 1e-8\n",
    "\n",
    "    def __call__(self, x):\n",
    "        if isinstance(x, torch.Tensor): x = x.numpy()\n",
    "        if self.normalize and self.mean is not None:\n",
    "            x = (x - self.mean) / self.std\n",
    "        if self.augment:\n",
    "            x = self._augment(x)\n",
    "        return torch.tensor(x, dtype=torch.float32)\n",
    "\n",
    "    def _augment(self, x):\n",
    "        T,C = x.shape\n",
    "        # jitter\n",
    "        if random.random()<0.9: x += np.random.normal(0,0.02,size=x.shape)\n",
    "        # scaling\n",
    "        if random.random()<0.8: x *= np.random.normal(1.0,0.1,size=(1,C))\n",
    "        # time mask\n",
    "        if random.random()<0.5:\n",
    "            m = int(T*0.1); s = random.randint(0, max(0,T-m-1)); x[s:s+m] = 0\n",
    "        # crop + pad back\n",
    "        if random.random()<0.7:\n",
    "            keep = int(T*0.9); s = random.randint(0, T-keep)\n",
    "            x = np.pad(x[s:s+keep], ((0,T-keep),(0,0)))\n",
    "        # segment permutation\n",
    "        if random.random()<0.3:\n",
    "            segs = np.array_split(x, 4, axis=0); random.shuffle(segs); x = np.concatenate(segs, axis=0)\n",
    "        return x\n",
    "\n",
    "\n",
    "class SimCLRDataset(Dataset):\n",
    "    \"\"\"Wrap base dataset to produce two augmented views.\"\"\"\n",
    "    def __init__(self, base: Dataset, transform: TimeSeriesTransform):\n",
    "        self.base = base; self.transform = transform\n",
    "    def __len__(self): return len(self.base)\n",
    "    def __getitem__(self, idx):\n",
    "        x,y = self.base[idx]\n",
    "        return self.transform(x), self.transform(x), y\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6473e047-e894-4091-9046-f378ba973767",
   "metadata": {},
   "source": [
    "### Cell 3 — Models & Losses & Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d78d7e63-2a3b-49d7-bdd0-bbdb6bd490c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------ Encoder ------------\n",
    "class Encoder1D(nn.Module):\n",
    "    \"\"\"CNN backbone; optional BiLSTM head; outputs L2-normalized embedding.\"\"\"\n",
    "    def __init__(self, in_channels=9, emb_dim=256, hidden=128, use_lstm=False, lstm_hidden=128):\n",
    "        super().__init__()\n",
    "        self.use_lstm = use_lstm\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv1d(in_channels,64,7,padding=3), nn.BatchNorm1d(64), nn.ReLU(),\n",
    "            nn.Conv1d(64,128,5,padding=2), nn.BatchNorm1d(128), nn.ReLU(),\n",
    "            nn.Conv1d(128,hidden,3,padding=1),    nn.BatchNorm1d(hidden), nn.ReLU(),\n",
    "            nn.AdaptiveAvgPool1d(32)\n",
    "        )\n",
    "        if use_lstm:\n",
    "            self.lstm = nn.LSTM(hidden, lstm_hidden, batch_first=True, bidirectional=True)\n",
    "            proj_in = lstm_hidden*2\n",
    "        else:\n",
    "            proj_in = hidden*32\n",
    "        self.proj = nn.Linear(proj_in, emb_dim)\n",
    "\n",
    "    def forward(self, x):        # x: [B,T,C]\n",
    "        x = x.transpose(1,2)     # [B,C,T]\n",
    "        h = self.conv(x)\n",
    "        if self.use_lstm:\n",
    "            h = h.transpose(1,2) # [B,T',H]\n",
    "            h,_ = self.lstm(h)\n",
    "            h = h.mean(dim=1)\n",
    "        else:\n",
    "            h = h.flatten(1)\n",
    "        z = F.normalize(self.proj(h), dim=-1)\n",
    "        return z\n",
    "\n",
    "# ------------ Heads ------------\n",
    "class ProjectionHead(nn.Module):\n",
    "    def __init__(self, in_dim=256, proj_dim=128):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(nn.Linear(in_dim,in_dim), nn.ReLU(), nn.Linear(in_dim,proj_dim))\n",
    "    def forward(self, x): return F.normalize(self.net(x), dim=-1)\n",
    "\n",
    "class ClassifierHead(nn.Module):\n",
    "    def __init__(self, in_dim=256, n_classes=6):\n",
    "        super().__init__()\n",
    "        self.fc = nn.Linear(in_dim, n_classes)\n",
    "    def forward(self, x): return self.fc(x)\n",
    "\n",
    "# ------------ Losses ------------\n",
    "class NTXentLoss(nn.Module):\n",
    "    def __init__(self, temperature=0.2): super().__init__(); self.t = temperature\n",
    "    def forward(self, z1, z2):\n",
    "        B = z1.size(0)\n",
    "        z = torch.cat([z1,z2], dim=0)          # [2B,D]\n",
    "        sim = torch.mm(z, z.t()) / self.t\n",
    "        mask = torch.eye(2*B, dtype=torch.bool, device=z.device)\n",
    "        sim.masked_fill_(mask, -9e15)\n",
    "        labels = torch.cat([torch.arange(B,2*B), torch.arange(0,B)], dim=0).to(z.device)\n",
    "        return F.cross_entropy(sim, labels)\n",
    "\n",
    "def coral_loss(source, target):\n",
    "    def cov(feat):\n",
    "        xm = feat - feat.mean(dim=0, keepdim=True)\n",
    "        return (xm.t() @ xm) / (feat.size(0)-1)\n",
    "    cs, ct = cov(source), cov(target)\n",
    "    return F.mse_loss(cs, ct)\n",
    "\n",
    "# ------------ DANN helper ------------\n",
    "class GradReverse(torch.autograd.Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, x, lam): ctx.lam = lam; return x.view_as(x)\n",
    "    @staticmethod\n",
    "    def backward(ctx, g): return -ctx.lam*g, None\n",
    "def grad_reverse(x, lam): return GradReverse.apply(x, lam)\n",
    "\n",
    "class DomainClassifier(nn.Module):\n",
    "    def __init__(self, in_dim=256, hidden=128):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(nn.Linear(in_dim,hidden), nn.ReLU(), nn.Linear(hidden,2))\n",
    "    def forward(self, x, lam=1.0): return self.net(grad_reverse(x, lam))\n",
    "\n",
    "# ------------ Evaluation ------------\n",
    "def evaluate(encoder, head, loader, device):\n",
    "    encoder.eval(); head.eval()\n",
    "    y_true, y_pred = [], []\n",
    "    with torch.no_grad():\n",
    "        for x,y in loader:\n",
    "            x = x.to(device)\n",
    "            logits = head(encoder(x))\n",
    "            y_true.append(y.numpy())\n",
    "            y_pred.append(logits.argmax(1).cpu().numpy())\n",
    "    y_true = np.concatenate(y_true); y_pred = np.concatenate(y_pred)\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    f1  = f1_score(y_true, y_pred, average=\"macro\")\n",
    "    cm  = confusion_matrix(y_true, y_pred)\n",
    "    return acc, f1, cm\n",
    "\n",
    "def domain_confusion_score(encoder, loader_src, loader_tgt, device):\n",
    "    \"\"\"Train a small linear domain classifier on frozen embeddings; report accuracy.\n",
    "       Lower accuracy = better alignment.\"\"\"\n",
    "    encoder.eval()\n",
    "    feats, dom = [], []\n",
    "    with torch.no_grad():\n",
    "        for x,_ in loader_src:\n",
    "            z = encoder(x.to(device)).cpu().numpy(); feats.append(z); dom.append(np.zeros(z.shape[0], int))\n",
    "        for x,_ in loader_tgt:\n",
    "            z = encoder(x.to(device)).cpu().numpy(); feats.append(z); dom.append(np.ones(z.shape[0], int))\n",
    "    X = torch.tensor(np.concatenate(feats), dtype=torch.float32).to(device)\n",
    "    y = torch.tensor(np.concatenate(dom), dtype=torch.long).to(device)\n",
    "    clf = nn.Linear(X.size(1), 2).to(device)\n",
    "    opt = torch.optim.Adam(clf.parameters(), lr=1e-3)\n",
    "    for _ in range(200):\n",
    "        loss = F.cross_entropy(clf(X), y)\n",
    "        opt.zero_grad(); loss.backward(); opt.step()\n",
    "    with torch.no_grad():\n",
    "        acc = (clf(X).argmax(1) == y).float().mean().item()\n",
    "    return acc\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9dc5053-566e-47e5-ae92-322ac186c3db",
   "metadata": {},
   "source": [
    "### Cell 4 — Self-Supervised Pretraining (SimCLR) — resumable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a1f6ce49-24b3-4520-9f20-aa1974e337d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pretrain_simclr_notebook(\n",
    "    uci_root=\"UCIHARDataset\",\n",
    "    batch_size=256, epochs=10, lr=1e-3, weight_decay=1e-4,\n",
    "    temperature=0.2, emb_dim=256, proj_dim=128, use_lstm=False,\n",
    "    ckpt_path=\"runs/simclr_src_last.pt\", seed=42\n",
    "):\n",
    "    set_seed(seed); ensure_dir(\"runs\"); dev = device\n",
    "\n",
    "    # Data (source = UCI HAR train)\n",
    "    src = UCIHARDataset(uci_root, \"train\")\n",
    "    t = TimeSeriesTransform(normalize=True, augment=True); t.fit(src.data)\n",
    "    loader = DataLoader(SimCLRDataset(src, t), batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "\n",
    "    in_ch = src[0][0].shape[1]\n",
    "    encoder = Encoder1D(in_channels=in_ch, emb_dim=emb_dim, use_lstm=use_lstm).to(dev)\n",
    "    proj    = ProjectionHead(in_dim=emb_dim, proj_dim=proj_dim).to(dev)\n",
    "    opt     = torch.optim.AdamW(list(encoder.parameters())+list(proj.parameters()), lr=lr, weight_decay=weight_decay)\n",
    "    crit    = NTXentLoss(temperature=temperature)\n",
    "\n",
    "    # Resume\n",
    "    start_epoch, losses = 0, []\n",
    "    if os.path.exists(ckpt_path):\n",
    "        cp = torch.load(ckpt_path, map_location=dev)\n",
    "        encoder.load_state_dict(cp[\"encoder\"], strict=False)\n",
    "        proj.load_state_dict(cp[\"proj\"], strict=False)\n",
    "        if \"optimizer\" in cp: opt.load_state_dict(cp[\"optimizer\"])\n",
    "        start_epoch = cp.get(\"epoch\", 0)\n",
    "        losses = cp.get(\"losses\", [])\n",
    "        print(f\"✅ Resuming SimCLR from epoch {start_epoch}\")\n",
    "\n",
    "    # Train\n",
    "    for ep in range(start_epoch+1, start_epoch+epochs+1):\n",
    "        encoder.train(); proj.train(); total=0.0\n",
    "        for v1,v2,_ in loader:\n",
    "            v1,v2 = v1.to(dev), v2.to(dev)\n",
    "            p1, p2 = proj(encoder(v1)), proj(encoder(v2))\n",
    "            loss = crit(p1,p2)\n",
    "            opt.zero_grad(); loss.backward(); opt.step()\n",
    "            total += loss.item()\n",
    "        avg = total/len(loader); losses.append(avg)\n",
    "        print(f\"[SimCLR] Epoch {ep}: loss={avg:.4f}\")\n",
    "        torch.save({\"epoch\":ep,\"encoder\":encoder.state_dict(),\"proj\":proj.state_dict(),\n",
    "                    \"optimizer\":opt.state_dict(),\"losses\":losses}, ckpt_path)\n",
    "\n",
    "    # Plot loss\n",
    "    plt.figure(figsize=(5,3)); plt.plot(losses, marker='o')\n",
    "    plt.title(\"SimCLR Training Loss\"); plt.xlabel(\"Epoch\"); plt.ylabel(\"Loss\"); plt.grid(True); plt.tight_layout(); plt.show()\n",
    "    return encoder, proj, losses\n",
    "\n",
    "# —— Run pretraining (adjust epochs as you like)\n",
    "# encoder_src, proj_src, _ = pretrain_simclr_notebook(epochs=10, batch_size=256)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4b6ae0af-1af3-44cf-9b87-6589d9e572cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_9275/3224549427.py:23: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  cp = torch.load(ckpt_path, map_location=dev)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Resuming SimCLR from epoch 100\n",
      "[SimCLR] Epoch 101: loss=1.8676\n",
      "[SimCLR] Epoch 102: loss=1.8621\n",
      "[SimCLR] Epoch 103: loss=1.8606\n",
      "[SimCLR] Epoch 104: loss=1.8571\n",
      "[SimCLR] Epoch 105: loss=1.8626\n",
      "[SimCLR] Epoch 106: loss=1.8566\n",
      "[SimCLR] Epoch 107: loss=1.8602\n",
      "[SimCLR] Epoch 108: loss=1.8599\n",
      "[SimCLR] Epoch 109: loss=1.8581\n",
      "[SimCLR] Epoch 110: loss=1.8525\n",
      "[SimCLR] Epoch 111: loss=1.8552\n",
      "[SimCLR] Epoch 112: loss=1.8572\n",
      "[SimCLR] Epoch 113: loss=1.8515\n",
      "[SimCLR] Epoch 114: loss=1.8524\n",
      "[SimCLR] Epoch 115: loss=1.8526\n",
      "[SimCLR] Epoch 116: loss=1.8505\n",
      "[SimCLR] Epoch 117: loss=1.8517\n",
      "[SimCLR] Epoch 118: loss=1.8538\n",
      "[SimCLR] Epoch 119: loss=1.8515\n",
      "[SimCLR] Epoch 120: loss=1.8468\n",
      "[SimCLR] Epoch 121: loss=1.8503\n",
      "[SimCLR] Epoch 122: loss=1.8547\n",
      "[SimCLR] Epoch 123: loss=1.8480\n",
      "[SimCLR] Epoch 124: loss=1.8449\n",
      "[SimCLR] Epoch 125: loss=1.8455\n",
      "[SimCLR] Epoch 126: loss=1.8505\n",
      "[SimCLR] Epoch 127: loss=1.8476\n",
      "[SimCLR] Epoch 128: loss=1.8504\n",
      "[SimCLR] Epoch 129: loss=1.8410\n",
      "[SimCLR] Epoch 130: loss=1.8442\n",
      "[SimCLR] Epoch 131: loss=1.8394\n",
      "[SimCLR] Epoch 132: loss=1.8446\n",
      "[SimCLR] Epoch 133: loss=1.8374\n",
      "[SimCLR] Epoch 134: loss=1.8403\n",
      "[SimCLR] Epoch 135: loss=1.8386\n",
      "[SimCLR] Epoch 136: loss=1.8397\n",
      "[SimCLR] Epoch 137: loss=1.8422\n",
      "[SimCLR] Epoch 138: loss=1.8370\n",
      "[SimCLR] Epoch 139: loss=1.8312\n",
      "[SimCLR] Epoch 140: loss=1.8316\n",
      "[SimCLR] Epoch 141: loss=1.8294\n",
      "[SimCLR] Epoch 142: loss=1.8315\n",
      "[SimCLR] Epoch 143: loss=1.8362\n",
      "[SimCLR] Epoch 144: loss=1.8343\n",
      "[SimCLR] Epoch 145: loss=1.8283\n",
      "[SimCLR] Epoch 146: loss=1.8323\n",
      "[SimCLR] Epoch 147: loss=1.8349\n",
      "[SimCLR] Epoch 148: loss=1.8347\n",
      "[SimCLR] Epoch 149: loss=1.8360\n",
      "[SimCLR] Epoch 150: loss=1.8331\n",
      "[SimCLR] Epoch 151: loss=1.8381\n",
      "[SimCLR] Epoch 152: loss=1.8301\n",
      "[SimCLR] Epoch 153: loss=1.8192\n",
      "[SimCLR] Epoch 154: loss=1.8282\n",
      "[SimCLR] Epoch 155: loss=1.8231\n",
      "[SimCLR] Epoch 156: loss=1.8286\n",
      "[SimCLR] Epoch 157: loss=1.8310\n",
      "[SimCLR] Epoch 158: loss=1.8289\n",
      "[SimCLR] Epoch 159: loss=1.8302\n",
      "[SimCLR] Epoch 160: loss=1.8267\n",
      "[SimCLR] Epoch 161: loss=1.8276\n",
      "[SimCLR] Epoch 162: loss=1.8265\n",
      "[SimCLR] Epoch 163: loss=1.8269\n",
      "[SimCLR] Epoch 164: loss=1.8278\n",
      "[SimCLR] Epoch 165: loss=1.8220\n",
      "[SimCLR] Epoch 166: loss=1.8236\n",
      "[SimCLR] Epoch 167: loss=1.8206\n",
      "[SimCLR] Epoch 168: loss=1.8185\n",
      "[SimCLR] Epoch 169: loss=1.8226\n",
      "[SimCLR] Epoch 170: loss=1.8237\n",
      "[SimCLR] Epoch 171: loss=1.8142\n",
      "[SimCLR] Epoch 172: loss=1.8200\n",
      "[SimCLR] Epoch 173: loss=1.8187\n",
      "[SimCLR] Epoch 174: loss=1.8244\n",
      "[SimCLR] Epoch 175: loss=1.8231\n",
      "[SimCLR] Epoch 176: loss=1.8183\n",
      "[SimCLR] Epoch 177: loss=1.8204\n",
      "[SimCLR] Epoch 178: loss=1.8210\n",
      "[SimCLR] Epoch 179: loss=1.8149\n",
      "[SimCLR] Epoch 180: loss=1.8126\n",
      "[SimCLR] Epoch 181: loss=1.8152\n",
      "[SimCLR] Epoch 182: loss=1.8199\n",
      "[SimCLR] Epoch 183: loss=1.8159\n",
      "[SimCLR] Epoch 184: loss=1.8162\n",
      "[SimCLR] Epoch 185: loss=1.8107\n",
      "[SimCLR] Epoch 186: loss=1.8075\n",
      "[SimCLR] Epoch 187: loss=1.8210\n",
      "[SimCLR] Epoch 188: loss=1.8175\n",
      "[SimCLR] Epoch 189: loss=1.8118\n",
      "[SimCLR] Epoch 190: loss=1.8122\n",
      "[SimCLR] Epoch 191: loss=1.8105\n",
      "[SimCLR] Epoch 192: loss=1.8173\n",
      "[SimCLR] Epoch 193: loss=1.8127\n",
      "[SimCLR] Epoch 194: loss=1.8100\n",
      "[SimCLR] Epoch 195: loss=1.8145\n",
      "[SimCLR] Epoch 196: loss=1.8075\n",
      "[SimCLR] Epoch 197: loss=1.8091\n",
      "[SimCLR] Epoch 198: loss=1.8142\n",
      "[SimCLR] Epoch 199: loss=1.8082\n",
      "[SimCLR] Epoch 200: loss=1.8064\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "encoder_src, proj_src, _ = pretrain_simclr_notebook(epochs=100, batch_size=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d5dd26e-8224-453a-a5aa-98825b23e055",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11a37ca1-1f90-4dd8-b233-8b2a60c7e246",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d07cde76-75a4-409c-89f9-37180b22c81a",
   "metadata": {},
   "source": [
    "### Cell 5 — Transfer: Linear Probe (freeze encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "76e7fe9b-682c-444e-957b-7bf291dfda79",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transfer_linear_notebook(\n",
    "    uci_root=\"UCIHARDataset\",\n",
    "    tgt_root=\"EpilepsyHAR_Realistic\",\n",
    "    ckpt=\"runs/simclr_src_last.pt\",\n",
    "    batch_size=256, epochs=10, lr=1e-3, emb_dim=256, use_lstm=False, tgt_classes=4\n",
    "):\n",
    "    dev = device\n",
    "    # Normalization from source\n",
    "    src_tr = UCIHARDataset(uci_root, \"train\")\n",
    "    tfm_src = TimeSeriesTransform(normalize=True, augment=False); tfm_src.fit(src_tr.data)\n",
    "\n",
    "    # Target loaders\n",
    "    tgt_tr = UCIHARDataset(tgt_root, \"train\")\n",
    "    tgt_te = UCIHARDataset(tgt_root, \"test\")\n",
    "\n",
    "    class Wrap(Dataset):\n",
    "        def __init__(self, base, tfm): self.base=base; self.tfm=tfm\n",
    "        def __len__(self): return len(self.base)\n",
    "        def __getitem__(self,i): x,y=self.base[i]; return self.tfm(x), y\n",
    "\n",
    "    tr = DataLoader(Wrap(tgt_tr, tfm_src), batch_size=batch_size, shuffle=True)\n",
    "    te = DataLoader(Wrap(tgt_te, tfm_src), batch_size=batch_size)\n",
    "\n",
    "    in_ch = tgt_tr[0][0].shape[1]\n",
    "    encoder = Encoder1D(in_channels=in_ch, emb_dim=emb_dim, use_lstm=use_lstm).to(dev)\n",
    "    head    = ClassifierHead(in_dim=emb_dim, n_classes=tgt_classes).to(dev)\n",
    "\n",
    "    # Load pretrained encoder & freeze\n",
    "    cp = torch.load(ckpt, map_location=dev); encoder.load_state_dict(cp[\"encoder\"], strict=False)\n",
    "    for p in encoder.parameters(): p.requires_grad=False\n",
    "\n",
    "    opt = torch.optim.Adam(head.parameters(), lr=lr)\n",
    "    for ep in range(1, epochs+1):\n",
    "        head.train()\n",
    "        for x,y in tr:\n",
    "            x,y = x.to(dev), y.to(dev)\n",
    "            with torch.no_grad(): z = encoder(x)\n",
    "            loss = F.cross_entropy(head(z), y)\n",
    "            opt.zero_grad(); loss.backward(); opt.step()\n",
    "        acc,f1,cm = evaluate(encoder, head, te, dev)\n",
    "        print(f\"[Linear] Epoch {ep}: acc={acc:.4f} f1={f1:.4f}\\nCM=\\n{cm}\")\n",
    "    return encoder, head\n",
    "\n",
    "# —— Run linear probe\n",
    "# enc_lin, head_lin = transfer_linear_notebook(epochs=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d613ff7-0946-49b2-9245-a08bdb3deddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_lin, head_lin = transfer_linear_notebook(epochs=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "206165b8-d869-4554-b9e7-1558637d207f",
   "metadata": {},
   "source": [
    "### Cell 6 — Transfer: Full Fine-Tuning (unfreeze)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b4b3d7ad-97ee-4144-9110-40c9aa150daa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transfer_finetune_notebook(\n",
    "    uci_root=\"UCIHARDataset\",\n",
    "    tgt_root=\"EpilepsyHAR_Realistic\",\n",
    "    ckpt=\"runs/simclr_src_last.pt\",\n",
    "    batch_size=256, epochs=10, lr=1e-3, weight_decay=1e-4,\n",
    "    emb_dim=256, use_lstm=False, tgt_classes=4\n",
    "):\n",
    "    dev = device\n",
    "    src_tr = UCIHARDataset(uci_root, \"train\")\n",
    "    tfm_src = TimeSeriesTransform(normalize=True, augment=False); tfm_src.fit(src_tr.data)\n",
    "\n",
    "    tgt_tr = UCIHARDataset(tgt_root, \"train\"); tgt_te = UCIHARDataset(tgt_root, \"test\")\n",
    "    class Wrap(Dataset):\n",
    "        def __init__(self, base, tfm): self.base=base; self.tfm=tfm\n",
    "        def __len__(self): return len(self.base)\n",
    "        def __getitem__(self,i): x,y=self.base[i]; return self.tfm(x), y\n",
    "    tr = DataLoader(Wrap(tgt_tr, tfm_src), batch_size=batch_size, shuffle=True)\n",
    "    te = DataLoader(Wrap(tgt_te, tfm_src), batch_size=batch_size)\n",
    "\n",
    "    in_ch = tgt_tr[0][0].shape[1]\n",
    "    encoder = Encoder1D(in_channels=in_ch, emb_dim=emb_dim, use_lstm=use_lstm).to(dev)\n",
    "    head    = ClassifierHead(in_dim=emb_dim, n_classes=tgt_classes).to(dev)\n",
    "\n",
    "    cp = torch.load(ckpt, map_location=dev); encoder.load_state_dict(cp[\"encoder\"], strict=False)\n",
    "    opt = torch.optim.AdamW(list(encoder.parameters())+list(head.parameters()), lr=lr, weight_decay=weight_decay)\n",
    "\n",
    "    for ep in range(1, epochs+1):\n",
    "        encoder.train(); head.train()\n",
    "        for x,y in tr:\n",
    "            x,y = x.to(dev), y.to(dev)\n",
    "            loss = F.cross_entropy(head(encoder(x)), y)\n",
    "            opt.zero_grad(); loss.backward(); opt.step()\n",
    "        acc,f1,cm = evaluate(encoder, head, te, dev)\n",
    "        print(f\"[FineTune] Epoch {ep}: acc={acc:.4f} f1={f1:.4f}\\nCM=\\n{cm}\")\n",
    "    return encoder, head\n",
    "\n",
    "# —— Run fine-tuning\n",
    "# enc_ft, head_ft = transfer_finetune_notebook(epochs=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f329e96-30bd-4b7a-9871-43dd5f409b45",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "enc_ft, head_ft = transfer_finetune_notebook(epochs=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4aedf41-820f-4b02-ab51-a99e2301bb35",
   "metadata": {},
   "source": [
    "### Cell 7 — DANN (Adversarial Domain Alignment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c321351-82ea-45a5-a4cc-6a55cb1a8fe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "35c3f417-e17b-4832-9b84-e442ac85b981",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dann_notebook_debug(\n",
    "    uci_root=\"UCIHARDataset\",\n",
    "    tgt_root=\"EpilepsyHAR_Realistic\",\n",
    "    ckpt=\"runs/simclr_src_last.pt\",\n",
    "    batch_size=256,\n",
    "    epochs=20,\n",
    "    lr=1e-3,\n",
    "    emb_dim=256,\n",
    "    use_lstm=False,\n",
    "    lambda_dom=0.5,\n",
    "    seed=42\n",
    "):\n",
    "    import math, random\n",
    "    set_seed(seed)\n",
    "    dev = device_autoselect()\n",
    "\n",
    "    # ---------------- Load datasets ----------------\n",
    "    src_tr = UCIHARDataset(uci_root, \"train\")\n",
    "    tgt_tr = UCIHARDataset(tgt_root, \"train\")\n",
    "    tgt_te = UCIHARDataset(tgt_root, \"test\")\n",
    "\n",
    "    # Force 0-based int labels\n",
    "    for ds in [src_tr, tgt_tr, tgt_te]:\n",
    "        ds.labels = ds.labels.astype(int)\n",
    "        ds.labels -= ds.labels.min()\n",
    "\n",
    "    src_classes = int(np.max(src_tr.labels)) + 1  # e.g., 6\n",
    "    tgt_classes = int(np.max(tgt_tr.labels)) + 1  # e.g., 4\n",
    "    print(f\"✅ Source classes: {src_classes}, Target classes: {tgt_classes}\")\n",
    "\n",
    "    # ---------------- Normalization ----------------\n",
    "    tfm = TimeSeriesTransform(normalize=True, augment=False)\n",
    "    tfm.fit(src_tr.data)\n",
    "\n",
    "    class Wrap(Dataset):\n",
    "        def __init__(self, base): self.base = base\n",
    "        def __len__(self): return len(self.base)\n",
    "        def __getitem__(self, i): x, y = self.base[i]; return tfm(x), y\n",
    "\n",
    "    src_loader = DataLoader(Wrap(src_tr), batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "    tgt_loader = DataLoader(Wrap(tgt_tr), batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "    tgt_val    = DataLoader(Wrap(tgt_te), batch_size=batch_size)\n",
    "\n",
    "    # ---------------- Models ----------------\n",
    "    in_ch = src_tr[0][0].shape[1]\n",
    "    encoder = Encoder1D(in_channels=in_ch, emb_dim=emb_dim, use_lstm=use_lstm).to(dev)\n",
    "    head_src = ClassifierHead(emb_dim, src_classes).to(dev)  # head matches SOURCE\n",
    "    dom = DomainClassifier(emb_dim).to(dev)                  # domain: 2 outputs\n",
    "\n",
    "    if os.path.exists(ckpt):\n",
    "        cp = torch.load(ckpt, map_location=dev)\n",
    "        encoder.load_state_dict(cp[\"encoder\"], strict=False)\n",
    "        print(\"🔹 Loaded pretrained encoder.\")\n",
    "\n",
    "    opt = torch.optim.AdamW(\n",
    "        list(encoder.parameters()) + list(head_src.parameters()) + list(dom.parameters()),\n",
    "        lr=lr\n",
    "    )\n",
    "\n",
    "    # ---------------- Training ----------------\n",
    "    for ep in range(1, epochs + 1):\n",
    "        encoder.train(); head_src.train(); dom.train()\n",
    "        total_loss = total_cls = total_dom = 0.0\n",
    "\n",
    "        for (xs, ys), (xt, _) in zip(src_loader, tgt_loader):\n",
    "            xs, ys, xt = xs.to(dev), ys.to(dev, dtype=torch.long), xt.to(dev)\n",
    "\n",
    "            # Gradient reversal schedule\n",
    "            p = (ep - 1 + random.random()) / epochs\n",
    "            lam = 2 / (1 + math.exp(-10 * p)) - 1\n",
    "\n",
    "            zs, zt = encoder(xs), encoder(xt)\n",
    "            logits_s = head_src(zs)\n",
    "\n",
    "            # -------- Debug checks for labels --------\n",
    "            if ys.min() < 0 or ys.max() >= logits_s.shape[1]:\n",
    "                print(f\"\\n❌ Source label mismatch! ys range [{ys.min().item()}, {ys.max().item()}], \"\n",
    "                      f\"expected < {logits_s.shape[1]}\")\n",
    "                raise ValueError(\"Source label out of range\")\n",
    "\n",
    "            cls_loss = F.cross_entropy(logits_s, ys)\n",
    "\n",
    "            # -------- Domain alignment --------\n",
    "            zcat = torch.cat([zs, zt], dim=0)\n",
    "            dom_logits = dom(zcat, lam)\n",
    "\n",
    "            dom_labels = torch.cat([\n",
    "                torch.zeros(zs.size(0), dtype=torch.long, device=dev),\n",
    "                torch.ones(zt.size(0), dtype=torch.long, device=dev)\n",
    "            ])\n",
    "\n",
    "            if dom_labels.min() < 0 or dom_labels.max() >= dom_logits.shape[1]:\n",
    "                print(f\"\\n❌ Domain label mismatch! dom_labels range [{dom_labels.min().item()}, \"\n",
    "                      f\"{dom_labels.max().item()}], expected < {dom_logits.shape[1]}\")\n",
    "                raise ValueError(\"Domain label out of range\")\n",
    "\n",
    "            dom_loss = F.cross_entropy(dom_logits, dom_labels)\n",
    "            loss = cls_loss + lambda_dom * dom_loss\n",
    "\n",
    "            opt.zero_grad(set_to_none=True)\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "            total_cls  += cls_loss.item()\n",
    "            total_dom  += dom_loss.item()\n",
    "\n",
    "        # -------- Evaluation on target domain --------\n",
    "        encoder.eval()\n",
    "        head_tgt = ClassifierHead(emb_dim, tgt_classes).to(dev)\n",
    "        opt_probe = torch.optim.Adam(head_tgt.parameters(), lr=1e-3)\n",
    "\n",
    "        # Small target linear probe\n",
    "        for _ in range(3):\n",
    "            for x, y in tgt_loader:\n",
    "                x, y = x.to(dev), y.to(dev)\n",
    "                with torch.no_grad(): z = encoder(x)\n",
    "                loss = F.cross_entropy(head_tgt(z), y)\n",
    "                opt_probe.zero_grad(); loss.backward(); opt_probe.step()\n",
    "\n",
    "        acc, f1, cm = evaluate(encoder, head_tgt, tgt_val, dev)\n",
    "        print(f\"[E{ep:02d}] total={total_loss/len(src_loader):.4f} cls={total_cls/len(src_loader):.4f} \"\n",
    "              f\"dom={total_dom/len(src_loader):.4f} | tgt acc={acc:.4f} f1={f1:.4f}\")\n",
    "        print(\"CM:\\n\", cm)\n",
    "\n",
    "    print(\"\\n✅ DANN training complete.\")\n",
    "    return encoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6a8f71b-b943-4a2f-8d24-899ad02eeacf",
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_dann = dann_notebook_debug(\n",
    "    epochs=30,\n",
    "    lambda_dom=0.5,\n",
    "    batch_size=256\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adc9df2e-4f9a-4822-8814-aa990ab46833",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9f3297d-09bb-47af-83d0-51d31b359b8c",
   "metadata": {},
   "source": [
    "### Cell 8 — Contrastive Alignment (prototype + optional CORAL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3d4cd0d4-eff3-481c-9380-5ee5c6a3acab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def align_contrastive_notebook(\n",
    "    uci_root=\"UCIHARDataset\",\n",
    "    tgt_root=\"EpilepsyHAR_Realistic\",\n",
    "    ckpt=\"runs/simclr_src_last.pt\",\n",
    "    batch_size=256, epochs=10, lr=1e-3, weight_decay=1e-4,\n",
    "    emb_dim=256, use_lstm=False,\n",
    "    supervise_source=True, use_coral=True, lambda_src=0.5, lambda_coral=0.1,\n",
    "    temperature=0.2, probe_epochs=3, seed=42\n",
    "):\n",
    "    import math, numpy as np, random\n",
    "    set_seed(seed)\n",
    "    dev = device_autoselect()\n",
    "\n",
    "    # ---------- Data ----------\n",
    "    src_tr = UCIHARDataset(uci_root, \"train\")\n",
    "    src_te = UCIHARDataset(uci_root, \"test\")\n",
    "    tgt_tr = UCIHARDataset(tgt_root, \"train\")\n",
    "    tgt_te = UCIHARDataset(tgt_root, \"test\")\n",
    "\n",
    "    # force 0-based int labels (safety)\n",
    "    for ds in (src_tr, src_te, tgt_tr, tgt_te):\n",
    "        ds.labels = ds.labels.astype(int)\n",
    "        ds.labels -= ds.labels.min()\n",
    "\n",
    "    src_classes = int(np.max(src_tr.labels)) + 1   # e.g., 6 (UCI HAR)\n",
    "    tgt_classes = int(np.max(tgt_tr.labels)) + 1   # e.g., 4 (Epilepsy)\n",
    "    print(f\"Source classes={src_classes} | Target classes={tgt_classes}\")\n",
    "\n",
    "    # normalization: fit on source, apply everywhere\n",
    "    tfm_src = TimeSeriesTransform(normalize=True, augment=False); tfm_src.fit(src_tr.data)\n",
    "\n",
    "    class Wrap(Dataset):\n",
    "        def __init__(self, base, tfm): self.base=base; self.tfm=tfm\n",
    "        def __len__(self): return len(self.base)\n",
    "        def __getitem__(self, i): x,y=self.base[i]; return self.tfm(x), y\n",
    "\n",
    "    src_loader = DataLoader(Wrap(src_tr, tfm_src), batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "    tgt_loader = DataLoader(Wrap(tgt_tr, tfm_src), batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "    tgt_val    = DataLoader(Wrap(tgt_te, tfm_src), batch_size=batch_size)\n",
    "    src_val    = DataLoader(Wrap(src_te, tfm_src), batch_size=batch_size)\n",
    "\n",
    "    # ---------- Model ----------\n",
    "    in_ch = src_tr[0][0].shape[1]\n",
    "    encoder = Encoder1D(in_channels=in_ch, emb_dim=emb_dim, use_lstm=use_lstm).to(dev)\n",
    "    head_src = ClassifierHead(emb_dim, src_classes).to(dev)      # head matches SOURCE label space\n",
    "\n",
    "    # load pretrained encoder (SimCLR)\n",
    "    if os.path.exists(ckpt):\n",
    "        try:\n",
    "            cp = torch.load(ckpt, map_location=dev)              # if your torch supports, you can do weights_only=True\n",
    "        except TypeError:\n",
    "            cp = torch.load(ckpt, map_location=dev)\n",
    "        encoder.load_state_dict(cp[\"encoder\"], strict=False)\n",
    "        print(\"🔹 Loaded pretrained encoder.\")\n",
    "\n",
    "    opt = torch.optim.AdamW(list(encoder.parameters())+list(head_src.parameters()), lr=lr, weight_decay=weight_decay)\n",
    "\n",
    "    # ---------- Target prototypes (K_tgt x D) ----------\n",
    "    K = tgt_classes\n",
    "    proto_tgt = torch.zeros(K, emb_dim, device=dev)\n",
    "    cnt_tgt   = torch.zeros(K, device=dev)\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def update_prototypes_tgt(z, y):\n",
    "        # z: [B,D], y: [B]\n",
    "        for k in range(K):\n",
    "            m = (y==k)\n",
    "            if m.any():\n",
    "                n = m.sum()\n",
    "                proto_tgt[k] = (proto_tgt[k]*cnt_tgt[k] + z[m].mean(0)*n) / (cnt_tgt[k]+n)\n",
    "                cnt_tgt[k] += n\n",
    "\n",
    "    # initialize prototypes from a pass over target train\n",
    "    encoder.eval()\n",
    "    with torch.no_grad():\n",
    "        for x,y in DataLoader(Wrap(tgt_tr, tfm_src), batch_size=batch_size):\n",
    "            z = encoder(x.to(dev))\n",
    "            update_prototypes_tgt(z, y.to(dev))\n",
    "\n",
    "    # ---------- Helper: small target linear probe for eval ----------\n",
    "    def eval_with_target_probe():\n",
    "        encoder.eval()\n",
    "        head_tgt = ClassifierHead(emb_dim, tgt_classes).to(dev)\n",
    "        opt_probe = torch.optim.Adam(head_tgt.parameters(), lr=1e-3)\n",
    "        tr = DataLoader(Wrap(tgt_tr, tfm_src), batch_size=batch_size, shuffle=True)\n",
    "        for _ in range(probe_epochs):\n",
    "            head_tgt.train()\n",
    "            for x,y in tr:\n",
    "                x,y = x.to(dev), y.to(dev)\n",
    "                with torch.no_grad(): z = encoder(x)\n",
    "                loss = F.cross_entropy(head_tgt(z), y)\n",
    "                opt_probe.zero_grad(); loss.backward(); opt_probe.step()\n",
    "        acc, f1, cm = evaluate(encoder, head_tgt, tgt_val, dev)\n",
    "        return acc, f1, cm\n",
    "\n",
    "    # ---------- Train ----------\n",
    "    for ep in range(1, epochs+1):\n",
    "        encoder.train(); head_src.train()\n",
    "        total, tot_cls, tot_align, tot_coral = 0.0, 0.0, 0.0, 0.0\n",
    "\n",
    "        for (xs, ys), (xt, yt) in zip(src_loader, tgt_loader):\n",
    "            xs, ys, xt, yt = xs.to(dev), ys.to(dev, dtype=torch.long), xt.to(dev), yt.to(dev, dtype=torch.long)\n",
    "            zs, zt = encoder(xs), encoder(xt)\n",
    "            loss = 0.0\n",
    "\n",
    "            # (A) optional source supervision (on 6-class head)\n",
    "            if supervise_source:\n",
    "                logits_s = head_src(zs)\n",
    "                # safety check\n",
    "                if ys.min() < 0 or ys.max() >= logits_s.shape[1]:\n",
    "                    raise ValueError(f\"Source labels out of range: {ys.min().item()}..{ys.max().item()} vs {logits_s.shape[1]}\")\n",
    "                cls = F.cross_entropy(logits_s, ys)\n",
    "                loss += lambda_src * cls\n",
    "                tot_cls += cls.item()\n",
    "\n",
    "            # (B) target contrastive to target prototypes (K_tgt)\n",
    "            # pull each zt to its class prototype; negatives are other prototypes\n",
    "            protos = F.normalize(proto_tgt.detach(), dim=-1)      # [K,D]\n",
    "            sim = torch.mm(F.normalize(zt, dim=-1), protos.t()) / temperature  # [B,K]\n",
    "            if yt.min() < 0 or yt.max() >= K:\n",
    "                raise ValueError(f\"Target labels out of range: {yt.min().item()}..{yt.max().item()} vs {K}\")\n",
    "            align = F.cross_entropy(sim, yt)\n",
    "            loss += align\n",
    "            tot_align += align.item()\n",
    "\n",
    "            # (C) optional CORAL (distribution alignment of zs vs zt)\n",
    "            if use_coral:\n",
    "                cr = coral_loss(zs, zt)\n",
    "                loss += lambda_coral * cr\n",
    "                tot_coral += cr.item()\n",
    "\n",
    "            opt.zero_grad(set_to_none=True)\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "\n",
    "            # momentum update prototypes with current batch (EMA-like)\n",
    "            with torch.no_grad():\n",
    "                update_prototypes_tgt(zt, yt)\n",
    "\n",
    "            total += loss.item()\n",
    "\n",
    "        # eval with target linear probe\n",
    "        acc, f1, cm = eval_with_target_probe()\n",
    "        dom_acc = domain_confusion_score(encoder, src_val, tgt_val, dev)\n",
    "\n",
    "        print(f\"[E{ep:02d}] total={total/len(src_loader):.4f} cls={tot_cls/len(src_loader):.4f} \"\n",
    "              f\"align={tot_align/len(src_loader):.4f} coral={tot_coral/len(src_loader):.4f} | \"\n",
    "              f\"tgt acc={acc:.4f} f1={f1:.4f} | dom_acc={dom_acc:.3f}\")\n",
    "        print(\"CM:\\n\", cm)\n",
    "\n",
    "    print(\"✅ Contrastive alignment finished.\")\n",
    "    return encoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cced875f-f45f-411c-a049-395b4f190636",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m enc_align \u001b[38;5;241m=\u001b[39m align_contrastive_notebook(\n\u001b[1;32m      2\u001b[0m     epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m,\n\u001b[1;32m      3\u001b[0m     supervise_source\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m      4\u001b[0m     use_coral\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m      5\u001b[0m     lambda_src\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.5\u001b[39m,\n\u001b[1;32m      6\u001b[0m     lambda_coral\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.1\u001b[39m\n\u001b[1;32m      7\u001b[0m )\n",
      "Cell \u001b[0;32mIn[12], line 11\u001b[0m, in \u001b[0;36malign_contrastive_notebook\u001b[0;34m(uci_root, tgt_root, ckpt, batch_size, epochs, lr, weight_decay, emb_dim, use_lstm, supervise_source, use_coral, lambda_src, lambda_coral, temperature, probe_epochs, seed)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21malign_contrastive_notebook\u001b[39m(\n\u001b[1;32m      2\u001b[0m     uci_root\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUCIHARDataset\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      3\u001b[0m     tgt_root\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpilepsyHAR_Realistic\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      8\u001b[0m     temperature\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m, probe_epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m, seed\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m\n\u001b[1;32m      9\u001b[0m ):\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmath\u001b[39;00m\u001b[38;5;241m,\u001b[39m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\u001b[38;5;241m,\u001b[39m \u001b[38;5;21;01mrandom\u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m     set_seed(seed)\n\u001b[1;32m     12\u001b[0m     dev \u001b[38;5;241m=\u001b[39m device_autoselect()\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;66;03m# ---------- Data ----------\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[1], line 18\u001b[0m, in \u001b[0;36mset_seed\u001b[0;34m(seed)\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mset_seed\u001b[39m(seed\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m):\n\u001b[1;32m     17\u001b[0m     random\u001b[38;5;241m.\u001b[39mseed(seed); np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mseed(seed)\n\u001b[0;32m---> 18\u001b[0m     torch\u001b[38;5;241m.\u001b[39mmanual_seed(seed); torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mmanual_seed_all(seed)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/torch/_compile.py:32\u001b[0m, in \u001b[0;36m_disable_dynamo.<locals>.inner\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     29\u001b[0m     disable_fn \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mdisable(fn, recursive)\n\u001b[1;32m     30\u001b[0m     fn\u001b[38;5;241m.\u001b[39m__dynamo_disable \u001b[38;5;241m=\u001b[39m disable_fn\n\u001b[0;32m---> 32\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m disable_fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py:632\u001b[0m, in \u001b[0;36mDisableContext.__call__.<locals>._fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    630\u001b[0m prior \u001b[38;5;241m=\u001b[39m _maybe_set_eval_frame(callback)\n\u001b[1;32m    631\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 632\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    633\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    634\u001b[0m     _maybe_set_eval_frame(prior)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/torch/random.py:46\u001b[0m, in \u001b[0;36mmanual_seed\u001b[0;34m(seed)\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcuda\u001b[39;00m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39m_is_in_bad_fork():\n\u001b[0;32m---> 46\u001b[0m     torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mmanual_seed_all(seed)\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmps\u001b[39;00m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mmps\u001b[38;5;241m.\u001b[39m_is_in_bad_fork():\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/torch/cuda/random.py:129\u001b[0m, in \u001b[0;36mmanual_seed_all\u001b[0;34m(seed)\u001b[0m\n\u001b[1;32m    126\u001b[0m         default_generator \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mdefault_generators[i]\n\u001b[1;32m    127\u001b[0m         default_generator\u001b[38;5;241m.\u001b[39mmanual_seed(seed)\n\u001b[0;32m--> 129\u001b[0m _lazy_call(cb, seed_all\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/torch/cuda/__init__.py:249\u001b[0m, in \u001b[0;36m_lazy_call\u001b[0;34m(callable, **kwargs)\u001b[0m\n\u001b[1;32m    247\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_lazy_call\u001b[39m(\u001b[38;5;28mcallable\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    248\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_initialized():\n\u001b[0;32m--> 249\u001b[0m         \u001b[38;5;28mcallable\u001b[39m()\n\u001b[1;32m    250\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    251\u001b[0m         \u001b[38;5;66;03m# TODO(torch_deploy): this accesses linecache, which attempts to read the\u001b[39;00m\n\u001b[1;32m    252\u001b[0m         \u001b[38;5;66;03m# file system to get traceback info. Patch linecache or do something\u001b[39;00m\n\u001b[1;32m    253\u001b[0m         \u001b[38;5;66;03m# else here if this ends up being important.\u001b[39;00m\n\u001b[1;32m    254\u001b[0m         \u001b[38;5;28;01mglobal\u001b[39;00m _lazy_seed_tracker\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/torch/cuda/random.py:127\u001b[0m, in \u001b[0;36mmanual_seed_all.<locals>.cb\u001b[0;34m()\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(device_count()):\n\u001b[1;32m    126\u001b[0m     default_generator \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mdefault_generators[i]\n\u001b[0;32m--> 127\u001b[0m     default_generator\u001b[38;5;241m.\u001b[39mmanual_seed(seed)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "source": [
    "enc_align = align_contrastive_notebook(\n",
    "    epochs=10,\n",
    "    supervise_source=True,\n",
    "    use_coral=True,\n",
    "    lambda_src=0.5,\n",
    "    lambda_coral=0.1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "786a05fd-5ec2-4946-89d2-94f4462ed451",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9ffc1b88-b84d-4dd0-bc51-af8d30bbbeb9",
   "metadata": {},
   "source": [
    "### Cell 9 — Confusion Matrix Visualization (from latest eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9f18dd9e-ae99-4d3e-9bcb-036e52ff121d",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'enc_align' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 12\u001b[0m\n\u001b[1;32m      9\u001b[0m     plt\u001b[38;5;241m.\u001b[39mtight_layout(); plt\u001b[38;5;241m.\u001b[39mshow()\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# Example usage AFTER running one of the transfer functions above:\u001b[39;00m\n\u001b[0;32m---> 12\u001b[0m acc, f1, cm \u001b[38;5;241m=\u001b[39m evaluate(enc_align, head_align, DataLoader(Wrap(UCIHARDataset(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpilepsyHAR_Realistic\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m\"\u001b[39m), tfm_src), batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m256\u001b[39m), device)\n\u001b[1;32m     13\u001b[0m plot_confusion_matrix(cm, [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTonic-Clonic\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMyoclonic\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAtonic\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAbsence\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n",
      "\u001b[0;31mNameError\u001b[0m: name 'enc_align' is not defined"
     ]
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "def plot_confusion_matrix(cm, class_names, title=\"Confusion Matrix (Normalized)\"):\n",
    "    cmn = cm.astype(float) / (cm.sum(axis=1, keepdims=True) + 1e-12)\n",
    "    plt.figure(figsize=(6,5))\n",
    "    sns.heatmap(cmn, annot=True, fmt=\".2f\", cmap=\"Blues\",\n",
    "                xticklabels=class_names, yticklabels=class_names)\n",
    "    plt.title(title); plt.xlabel(\"Predicted\"); plt.ylabel(\"True\")\n",
    "    plt.tight_layout(); plt.show()\n",
    "\n",
    "# Example usage AFTER running one of the transfer functions above:\n",
    "acc, f1, cm = evaluate(enc_align, head_align, DataLoader(Wrap(UCIHARDataset(\"EpilepsyHAR_Realistic\",\"test\"), tfm_src), batch_size=256), device)\n",
    "plot_confusion_matrix(cm, [\"Tonic-Clonic\",\"Myoclonic\",\"Atonic\",\"Absence\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3683bf0-af04-4bc6-8691-9c4201dd7773",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
